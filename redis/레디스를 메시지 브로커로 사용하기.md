메시지 브로커는 크게 **메시징 큐**와 **이벤트 스트림**이라는 두 가지 형태로 나눌 수 있다.

- 메시징 큐에서는 주로 데이터를 생성하는 쪽을 생산자(Producer), 데이터를 수신하는 쪽을 소비자(Consumer)로 지칭한다. 
- 이벤트 스트림에서는 데이터를 생성하는 쪽을 발행자(Publisher), 데이터를 조회하는 쪽을 구독자(Subscriber)로 지칭한다.

메시징 큐와 이벤트 스트림은 크게 두 가지 차이점을 가지고 있다.

## 방향성

### 메세징 큐

생산자는 소비자의 큐로 직접 데이터를 푸시 한다.
만약 소비자가 2개라면 2개의 서비스에 각각 메시지를 푸시 해야 하는 것이다.

### 이벤트 스트림

특정 저장소에 하나의 메시지를 보낼 수 있고, 메시지를 읽어가고자 하는 소비자들은 스트림에서 같은 메시지를 풀(pull)해 갈 수 있기 때문에 메시지를 복제해서 저장하지 않아도 된다.

## 데이터의 영속성

### 메시징 큐

소비자가 데이터를 읽어갈 때 큐에서 데이터를 삭제한다.
그렇기 때문에 메시지를 보내는 도중 새로운 소비자를 추가할때 메시징 큐를 이용한다면 소비자는 새롭게 추가된 이후의 이벤트만 확인할 수 있다.
따라서 메시징 큐는 1:1 상황에서 한 서비스가 다른 서비스에게 동작을 지시 할 때 유용하게 사용된다.

### 이벤트 스트림

구독자가 읽어간 데이터는 바로 삭제되지 않고 저장소의 설정에 따라 특정 기간 동안 저장될 수 있다.
스트림 방식은 메시징 큐와 다르게 메시지를 생산할 때 구독자를 지정하지 않고 스트림에 쌓인 데이터는 일정 기간 동안 지워지지 않기 때문에 새로 추가된 서비스도 스트림에 남아 있는 이전 데이터의 히스토리를 볼 수 있다.
따라서 스트림은 N:N 다대다 상황에서 유리하다.

### 레디스를 메시지 브로커로 사용하기

레디스에서 제공하는 pub/sub을 사용하면 빠르고 간단한 방식으로 메시지를 전달할 수 있는 메시지 브로커를 구현 할 수 있다.
발행자가 특정한 채널에 데이터를 전송하면 이 채널을 듣고 있는 모든 소비자는 데이터를 바로 소비할 수 있다. 레디스의 pub/sub에서 모든 데이터는 한 번 채널 전체에 전파된 뒤 삭제되는 일회성의 특징을 가지며 메시지가 잘 전달됐는지 등의 정보는 보장하지 않는다. 따라서 완벽하게 메시지가 전달돼야 하는 상황에는 적합하지 않을 수 있다.

#### list 자료 구조

list 자료 구조는 메시징 큐로 사용하지게 알맞다. list의 데이터는 푸시와 팝이 가능하며 애플리케이션은 list에 데이터가 있는지 매번 확인할 필요 없이 대기하다 list에 새로운 데이터가 들어오면 읽어갈 수 있는 **블로킹 기능**을 사용할 수도 있다.

#### stream

stream을 사용하면 레디스를 완벽한 스트림 플랫폼으로 사용할 수 있다. 카프카를 본따 만들어 데이터는 계속 추가되는 방식으로 저장된다.(append-only) 소비자와 소비자 그룹이라는 개념을 이용하면 카프카에서와 비슷하게 데이터의 분산 처리를 구현할 수 있다. stream에 저장되는 메시지를 실시간으로 리스닝하며 소비할 수도 있으며, 자장돼 있는 데이터를 시간대별로 검색하는 것도 가능하다.

## 레디스의 pub/sub

레디스는 아주 가벼운 pub/sub을 제공한다.
레디스 노드에 접근할 수 있는 모든 클라이언트는 발행자와 구독자가 될 수 있다. 발행자는 특정 채널에 메세지를 보낼 수 있으며, 구독자는 특정 채널을 리스닝하다가 메시지를 읽어갈 수 있다.

레디스에서 pub/sub은 매우 가볍기 때문에 최소한의 메시지 전달 기능만 제공한다. 발생자는 메시지를 채널로 보낼 수 있을 뿐, 어떤 구독자가 메시지를 읽어가는지 정상적으로 모든 구독자에게 메시지가 전달됐는지 확인할 수 없다. 구독자 또한 메시지를 발을 수 있지만 해당 메시지가 언제 어떤 발행자에 의해 생성됐는지 등의 메타데이터는 알 수 없다.

한 번 전파된 데이터는 레디스에 저장되지 않으며 **메시지의 통로 역할**만 한다. 그렇기에 정합성이 중요한 데이터를 전달하기에는 적합하지 않을 수 있다.

#### 메시지 publish하기

- PUBLISH - 데이터를 전파 할 수 있다.
```
PUBLISH hello world
(integer) 1
```

이렇게하면 hello라는 채널을 수신하고 있는 모든 서버들에 world라는 메시지가 전파된다. 전파 후 리턴은 구독자 수가 반환된다.

#### 메시지 구독하기

- SUBSCRIBE - 특정 채널을 구독할 수 있다.
```SUBSCRIBE event1 event2
Reading message... (press ~~)
1) "subscirbe"
2) "event1"
3) (integer) 1
1) "subscribe"
2) "event2"
3) (integer) 2
```

이렇게하면 동시에 event1과 event2를 구독하기 시작한다. 클라이언트가 구독자로 동작할 때에는 새로운 채널을 구독할 수 있지만 pub/sub과 관련되지 않은 다른 커맨드를 수행할 수 없다.

##### 구독자가 수행할 수 있는 커맨드
- SUBSCRIBE
- SSUBSCRIBE
- SUNSUBSCRIBE
- PSUBSCRIBE
- UNSUBSCRIBE
- PUNSUBSCRIBE
- PING
- RESET
- QUIT

PSUBSCRIBE 커맨드를 쓰면 일치하는 패턴에 해당 채널을 한 번에 구독 가능하다.
```
PSUBSCRIBE mail-*
Reading message...
1) "psubscribe"
2) "mail-*"
3) (integer) 1
```

mail- 로 시작하는 모든 채널에 전파된 메세지를 수신할 수 있다. SUBSCRIBE와 마찬가지로 동시에 여러 문자열을 구독하는 것도 가능하다. 이때 메시지는 message가 아닌 pmessage 타입으로 전달되 SUBSCRIBE을 사용해 메시지를 구독하는 방식과 구분된다.

## 클러스터 구조에서의 pub/sub

레디스 클러스터에서 pub/sub을 사용하면 메시지가 발행될때 해당 메시지는 클러스터에 속한 **모든 노드에 자동으로 전달된다.** 따라서 레디스 클러스트 아무 노드에 연결해 SUBSCRIBE을 사용하면 데이터를 수신 할 수 있다.
하지만 이 방법은 모든 클러스터에 메세지가 전파되기에 클러스터의 주요 목적을 고려한다면 비효율적인 방식이다. 모든 노드에 복제되는 방식은 클러스터 환경의 핵심 목표와는 부합하지 않으며 이로 인해 **불필요한 리소스 사용과 네트워크 부하가 발생할 수 있다.**

#### sharded pub/sub

위의 비효율을 해결하기 위해 레디스 7.0에서는 sharded pub/sub 기능이 도입됐다.
sharded pub/sub 환경에서는 각 채널은 **슬롯**에 매핑된다. 클러스터에서 키가 슬롯에 할당되는 것과 동일한 방식으로 채널이 할당되며, 같은 슬롯을 가지고 있는 노드 간에만 pub/sub 메시지를 전파한다.

sharded pub/sub을 이용하면 클러스터 구조에서 pub/sub되는 메시지는 모든 노드로 전파되지 않기 때문에 불필요한 복제를 줄여 자원을 절약할 수 있다는 장점이 있다.

# 레디스의 list를 메시징 큐로 사용하기

레디스의 list는 큐로 사용하기 좋음. 큐의 tail과 head에서 데이터를 넣고 뺄 수있는 커맨드가 존재해 애플리케이션 특성에 맞는 메시징 큐를 직접 구현할 수 있다.

## list의 EX 기능

트위터는 각 유저의 타임라인 캐시 데이터를 레디스에서 list 자료 구조로 관리함.

새로운 유저가 트윗을 작성할때 A를 팔로우 하는 유저의 타임라인 캐시에 저장됨.

list에 이미 존재할 때에만 아이템을 추가하면 자주 들어오지 않는 유저에 대해서는 캐시처리를 할 필요가 없어 짐.

사용자의 캐시가 존재하는지 안하는지의 유무를 애플리케이션에서 확인하지 않고 레디스에서 제어해 불필요한 과정을 줄여 성능을 향상 시킨다.

## list의 블로킹 기능

레디스를 **이벤트 큐**로 사용 할 경우 블로킹 기능 또한 유용하게 사용할 수 있음.

Event Driven 구조에서 시스템은 이벤트 큐에서 이벤트 루프를 돌며 신규로 처리할 이벤트가 있는지 확인함.

이걸 폴링이라 하는데 폴링은 프로세스가 진행되는 동안 애플리케이션과 큐의 리소스가 불필요하게 소모됨.

그리고 폴링은 주기적으로 돌기에 이벤트를 즉시 처리할 수 없다는 단점이 있음.

이때 list의 블로킹 기능을 사용하면 이와 같은 불필요함을 줄일 수 있음.

요청시 데이터가 있으면 반환하고 없으면 대기하고 있다 nil을 반환할 수 있음.

## list를 이용한 원형 큐

만약 특정 아이템을 계속해서 반복 접근해야 하는 클라이언트, 다중 클라이언트가 병렬적으로 같은 아이템에 접근해야 하는 클라이언트에서는 원형 큐 (링 버퍼)를 이용해 아이템을 처리 할 수있다.

## Stream

Stream은 레디스 5.0에서 새로 추가된 자료 구조로 대용량, 대규모의 메시징 데이터를 빠르게 처리할 수 있도록 설계됐다.

stream은 데이터를 계속해서 추가하는 방식으로 저장되는 자료 구조다. (append-only)

stream은 사용 목적에 따라 크게 두 가지 방식으로 활용될 수있음.

1) 백엔드 개발자를 위한 대량의 데이터를 효율적으로 처리하는 플랫폼으로 활용
2) 데이터 엔지니어를 위한 여러 생산자가 생성한 데이터를 다양한 소비자가 처리할 수 있게 지원하는 데이터 저장소 및 중간 큐잉 시스템으로 사용

### Stream 이란?

CS에서 스트림이란 연속적인 데이터의 흐름, 일정한 데이터 조각의 연속을 의미한다.

![MySQL's Data Streaming : What is it & How it works ? - DEV Community](https://res.cloudinary.com/practicaldev/image/fetch/s--ym-6T2sj--/c_imagga_scale,f_auto,fl_progressive,h_420,q_auto,w_1000/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/je4foy8k6q1nu0ngyw6b.png)

끝이 정해지지 않고 계속되는 불규칙한 데이터를 연속으로 반복 처리할 때 이또한 스트림 처리를 한다고 부를 수 있다.

아래와 같이 여러 곳에서 받을 데이터를 다른 곳으로 보내는 것도 연속적인 데이터의 전달을 의미하기 때문에 스트림이라 할 수 있다.
![Streaming Data Architecture in 2023: Components & Examples | Upsolver](https://www.upsolver.com/wp-content/uploads/2022/01/pasted-image-0-1.png)

이벤트를 스트리밍 방식으로 처리하는 것은 편리하지만 직접 이러한 스트리밍 플랫폼을 구축하는 것은 어렵기에 카프카나 레디스의 stream과 같은 서비스를 활용하면 스트림 데이터 처리를 더 쉽고 정확하게 수행할 수 있음.

스트리밍 플랫폼을 시스템 중심에 도입해 모든 데이터를 처리 스트리밍 플랫폼을 통해 수행함으로써 시스템이 마주한 다양한 문제를 해결할 수 있다.

### 데이터의 저장

#### 메시지의 저장과 식별

카프카에서 스트림 데이터는 토픽이라는 개념에 저장됨.

토픽은 각각 분리된 스트림을 뜻하며 같은 데이터를 관리하는 하나의 그룹을 의미함.

레디스에서는 하나의 stream 자료 구조가 하나의 stream을 의미함.

레디스에서 stream은 하나의 키에 연결된 자료 구조임.

![](https://redis.com/wp-content/uploads/2019/07/data-structures-_lists.svg?&auto=webp&quality=85,75&width=500)

카프카는 각 메시지가 0부터 시작해 증가하는 시퀀스 넘버로 식별가능한데 이 시퀀스넘버는 파티션 안에서만 유니크하기에 다른 파티션의 값의 경우 중복이 될 수 있어 유니크하게 식별되지 못한다.

레디스 stream에서 각 메시지는 시간과 관련된 유니크한 ID를 가지며 이 값은 중복 되지 않는다.

ID는 다음과 같이 2개의 파트로 나뉨

```
<millisecondsTime>-<sequenceNumber>
```

밀리세컨드 파는 실제 stream에 아이템이 저장될 시점의 레디스 노드 로컬 시간임.

시퀀스 파트는 동일한 밀리세컨드 시간에 여러 아이템이 저장될 수 있기에 같은 밀리세컨드에 저장된 데이터의 순서를 의미한다.

시퀀스 번호는 64bit으로 사실상 하나의 밀리세컨드 내에 생성할 수 있는 항목의 수는 제한이 없다.

모든 데이터는 유니크한 ID를 가지며 이 ID 값이 곧 시간을 의미하기 떄문에 시간을 이용해 특정 데이터를 검색 할 수 있다.

### 스트림 생성과 데이터 입력

레디스의 stream은 데이터를 저장하면 데이터의 저장과 동시에 stream 자료 구조가 생성된다.

stream은 hash 처럼 key-value로 저장되기에 각 메시지마다 유동 적인 데이터를 저장 할 수 있다.

### 데이터의 조회

레디스 stream에서는 두가지 방식으로 데이터를 읽을 수 있다.

1) 실시간으로 처리되는 데이터를 리스닝
2) ID를 이용해 필요한 데이터를 검색

### 소비자와 소비자 그룹

같은 데이터를 여러 소비자에게 전달하는 것을 팬아웃(fan-out)이라 함.

stream을 이용해 이벤트 데이터를 처리하는 상황에서 이벤트의 처리 성능을 높이기 위해 여러 소비자를 이용해 한 번에 여러 이벤트를 병렬적으로 처리되도록 구성할 수 있다. 이 때 레디스는 데이터가 순서대로 저장되기에 순서를 보장할 수 있다.

#### 소비자 그룹

stream에서 소비자 그룹 내의 한 소비자는 다른 소비자가 아직 읽지 않은 데이터만을 읽어간다.

각 요청 시마다 소비자는 stream에서 차례대로 데이터를 가져오게 된다.

레디스 stream에서 소비자 그룹은 stream의 상태를 나타내는 개념으로 간주 된다.

보류된 메시지의 관리 방식, 새로운 메시지를 요청하는 소비자가 매번 새로운 메시지의 ID를 할당받을 수 있는 방법을 이해하기 쉬워질것이다.(??)

stream은 파티션이라는 분할 없이도 소비자 그룹이라는 개념을 이용해 여러 소비자에게 stream의 데이터를 분산시킬 수 있다는 특징이 있다.

stream과 소비자 그룹은 독립적으로 동작할 수 있다.

Email이라는 stream 메시지를 읽어가기 위한 소비자 그룹은 다수 존재할 수 있고 각각 독립적으로 동작함.

소비자 그룹 1의 소비자가 a라는 메시지를 읽었으면 같은 그룹에서는 그 메시지를 다시 읽을 수 없지만 소비자 그룹 2 혹은 일반적인 다른 소비자에서는 해당 메시지를 읽을 수 있음.

하나의 소비자 그룹에서 여러개의 stream을 리스닝하는 것도 가능함.

소비자 그룹에 전달되는 모든 데이터는 시간 순으로 정렬돼 있으며 stream에 쌓인 메시지는 해당 데이터가 필요한 여러 서비스로 분산돼 읽힐 수 있음.